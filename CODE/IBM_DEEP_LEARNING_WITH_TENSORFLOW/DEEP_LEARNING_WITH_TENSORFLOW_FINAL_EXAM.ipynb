{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP LEARNING WITH TENSORFLOW - FINAL EXAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 - To create a pipeline of operations and its corresponding values to be \n",
    "#       parsed\n",
    "\n",
    "# To create a pipeline of operations and its corresponding values to be parsed\n",
    "\n",
    "# Why use a Data Flow graph to solve Mathematical expressions?\n",
    "# OK To create a pipeline of operations and its corresponding values to be \n",
    "#    parsed\n",
    "\n",
    "# To represent the expression in a human-readable form\n",
    "# To show the expression in a GUI\n",
    "# Because it is only way to solve mathematical expressions in a digital\n",
    "# computer\n",
    "# None of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 - A function that triggers a neuron and generate the outputs\n",
    "\n",
    "# What is an Activation Function\n",
    "# All of the above\n",
    "# A function that models a phenomenon or process\n",
    "# A function that triggers a neuron and generate the outputs----- OK ------\n",
    "# A function to normalize the output\n",
    "# None of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 - All of the above\n",
    "\n",
    "# Why TensorFlor is considered fast and suitable for Deep Learning?\n",
    "# it is suitable to operate over large and multidimensional tensors\n",
    "# runs on CPU\n",
    "# its core is based on C++\n",
    "# runs on GPU\n",
    "# All of the above--------------------------- OK ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4 - No, whatsoever\n",
    "\n",
    "# TensorFlow can replace Numpy?\n",
    "# None of the above --- fauX\n",
    "# No, whatsoever ----------------- OK ------------------------\n",
    "# Only with numpy, we canâ€™t solve Deep Learning problems, therefore TensorFlow\n",
    "# is required\n",
    "# Yes, completely\n",
    "# Partially for some operations on tensors, such as minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 - Fully connects to all neurons in all the layers\n",
    "\n",
    "# What is FALSE about Convolution Neural Networks(CNN)\n",
    "# Fully connects to all neurons in all the layers---------- OK ------------\n",
    "# connects only to neurons in local region(kernel size) of input image\n",
    "# builds feature maps hierarchically in every layer\n",
    "# Inspired by human visual system \n",
    "# None of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6 - The number of pixels, kernel should be moved.\n",
    "\n",
    "# What does \"Strides\" in Maxpooling Mean\n",
    "# The number of pixels, kernel should add.\n",
    "# The number of pixels, kernel should be moved.------------- OK --------------\n",
    "# The size of kernel.\n",
    "# The number of pixels, kernel should remove.\n",
    "# None of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7 - size of Input Image is reduced for \"VALID\" padding.\n",
    "\n",
    "# What is TRUE about \"Padding\" in Convolution\n",
    "# size of Input Image is reduced for \"VALID\" padding.-------------- OK -----\n",
    "# Size of Input Image is reduced for \"SAME\" padding.\n",
    "# Size of Input Image is Increased for \"SAME\" padding.\n",
    "# Size of input image is increased for \"VALID\" padding.\n",
    "# All of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8 - (0, Max)\n",
    "\n",
    "# Which of the following best describes Relu Function\n",
    "# (-1,1)\n",
    "# (0,5)\n",
    "# (0, Max)--------------- OK ---------------------\n",
    "# (-inf,inf)\n",
    "# (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9 - LSTM \n",
    "\n",
    "# Which ones are types of Recurrent Neural Networks?\n",
    "# Hopfield Network\n",
    "# Elman Networks and Jordan Networks\n",
    "# Recursive Neural Network\n",
    "# Deep Belief Network\n",
    "# LSTM-------------------- OK ------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10 - RNNs are VERY suitable for sequential data\n",
    "\n",
    "# What is TRUE about RNNs\n",
    "# RNNs can predict the future\n",
    "# RNNs are VERY suitable for sequential data------------- OK --------------\n",
    "# RNNs are NOT suitable for sequential data\n",
    "# RNNs are ONLY suitable for sequential data\n",
    "# All of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11 - All of the above\n",
    "\n",
    "# What is the problem with RNNs and gradients?\n",
    "# Numerical computation of gradients can drive into instabilities\n",
    "# Gradients can quickly drop and stabilize at near zero\n",
    "# Propagation of errors due to the recurrent characteristic\n",
    "# Gradients can grow exponentially\n",
    "# All of the above---------------- OK ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q12 - Long Short Term Memory\n",
    "\n",
    "# What type of RNN would you use in a NLP project to predict the next work in\n",
    "# a phrase? (only one is correct)\n",
    "# Bi-directional RNN\n",
    "# Neural history compressor\n",
    "# Long Short Term Memory--------------------- OK --------------------\n",
    "# Echo state network\n",
    "# None of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q13 - By minimizing the difference between inputs and outputs, while  the\n",
    "#       weighting features in the\n",
    "\n",
    "# How RBM can reduce the number of features?\n",
    "# By transforming the features using a kernel function\n",
    "# By randomly filtering out a few features then checking if the input can be \n",
    "# regenerated\n",
    "# By minimizing the difference between inputs and outputs, while weighting the\n",
    "# features in the----------------- OK --------------------\n",
    "# By cutting of features with less variance\n",
    "# All of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q14 - Both can cluster the data\n",
    "\n",
    "# How Autoencoders compares to K-means?\n",
    "# Autoencoders are always faster than k-means\n",
    "# Both are based on Neural Networks\n",
    "# K-Means is always better than Autoencoders\n",
    "# Both can cluster the data------------------ OK ------------------\n",
    "# None of the Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q15 - Dimensionality Reduction\n",
    "\n",
    "# Select all possible uses of Autoencoders and RBM (select all that applies)\n",
    "# Predict data in time series\n",
    "# Pattern Recognition\n",
    "# Dimensionality Reduction-------------------- OK ----------------\n",
    "# Clustering\n",
    "# All of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q16 - It makes automatic predictions for a user by collecting information \n",
    "#       from many users\n",
    "\n",
    "# What is TRUE about Collaborative Filtering\n",
    "# it is a technique used by Recommender Systems\n",
    "# None of the Above\n",
    "# It makes automatic predictions for a user by collecting information from \n",
    "# many users-------------------- OK --------------------------\n",
    "# RBM can be used to implement a collaborative filter\n",
    "# It is Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q17 - The size of input and Last Layers must be of Same dimensions\n",
    "\n",
    "# Which of the statements is TRUE for training Autoencoders:\n",
    "# The Size of Last Layer must atleast be 10% of Input layer DImension\n",
    "# The size of input and Last Layers must be of Same dimensions---- OK ---- \n",
    "# The Last Layer must be Double the size of Input Layer Dimension\n",
    "# The Last Layer must be half the size of Input Layer Dimension\n",
    "# None of the Above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q18 - All of the Above\n",
    "\n",
    "# To Design a Deep Autoencoder Architecture, what factors are to be considered:\n",
    "# The Size of centre most layer has to be close to number of Important Features\n",
    "# to be extracted.\n",
    "# The Centre most Layer should have smallest size compared to all other layers\n",
    "# The Network should have odd number of Layers\n",
    "# All the layers must be symmetrical with respect to centre most layer\n",
    "# All of the Above------------------- OK --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q19 - All of the Above-\n",
    "\n",
    "# With is True about Backpropogation:\n",
    "# Can be used to train LSTM ---incorrect\n",
    "# Can be used to train CNN\n",
    "# Can be used to train RBM\n",
    "# Can be used to train Autoencoders\n",
    "# All of the Above------------------------- OK --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q20 - Add more Hidden Layers to the Network\n",
    "\n",
    "# How Autoencoder can be Improved to handle Higly nonlinear Data:\n",
    "# Use Genetic Algorithms\n",
    "# Add more Hidden Layers to the Network--------------- OK ----------------\n",
    "# Use Higher initial Weight Values\n",
    "# Use lower initial weight Values\n",
    "# All of the Above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
