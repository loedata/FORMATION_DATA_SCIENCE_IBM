{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARK FUNDAMENTALS I - FINAL EXAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 - Transformation\n",
    "#      Action\n",
    "\n",
    "# . Which of the following is a type of Spark RDD operation? Select all that \n",
    "# apply.\n",
    "# Parallelization\n",
    "# Action--------------------------------- OK ---------------------\n",
    "# Persistence\n",
    "# Transformation------------------------- OK ---------------------\n",
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 - False\n",
    "\n",
    "# Spark must be installed and run on top of a Hadoop cluster. True or false\n",
    "# True\n",
    "# False------------------------ OK -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 - Average\n",
    "\n",
    "# Which of the following operations will work improperly when using a Combiner?\n",
    "# Count\n",
    "# Maximum\n",
    "# Minimum\n",
    "# Average---------------------- OK -------------------------\n",
    "# All of the above operations will work properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4 - All of the above\n",
    "\n",
    "# Spark supports which of the following libraries?\n",
    "# GraphX\n",
    "# Spark Streaming\n",
    "# MLlib\n",
    "# Spark SQL\n",
    "# All of the above------------------ OK --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 - Scala, Python, Java, R\n",
    "\n",
    "# Spark supports which of the following programming languages?\n",
    "# C++ and Python\n",
    "# Scala, Java, C++, Python, Perl\n",
    "# Scala, Perl, Java\n",
    "# Scala, Python, Java, R------------------- OK -------------------------\n",
    "# Java and Scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6 - False\n",
    "\n",
    "# A transformation is evaluated immediately. True or false?\n",
    "# True\n",
    "# False----------------------- OK ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7 - MEMORY_ONLY\n",
    "\n",
    "# # Which storage level does the cache() function use?\n",
    "# MEMORY_AND_DISK_SER\n",
    "# MEMORY_AND_DISK\n",
    "# MEMORY_ONLY_SER\n",
    "# MEMORY_ONLY--------------------- OK --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8 - They are read-only\n",
    "\n",
    "# Which of the following statements does NOT describe accumulators?\n",
    "# They can only be read by the driver\n",
    "# Programmers can extend them beyond numeric types\n",
    "# They implement counters and sums\n",
    "# They can only be added through an associative operation\n",
    "# They are read-only--------------------- OK -----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9 - True\n",
    "\n",
    "# ou must explicitly initialize the SparkContext when creating a Spark\n",
    "# application. True or false?\n",
    "# True------------------------- OK -----------------------\n",
    "# False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10 - True \n",
    "\n",
    "# The \"local\" parameter can be used to specify the number of cores to use for the application. True or false?\n",
    "# True------------------- OK ------------------------\n",
    "# False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11 - False\n",
    "\n",
    "# Spark applications can ONLY be packaged using one, specific build tool. \n",
    "# True or false?\n",
    "# True\n",
    "# False------------------ OK --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q12 - master\n",
    "\n",
    "# Which of the following parameters of the “spark-submit” script determine \n",
    "# where the application will run?\n",
    "# --class\n",
    "# --master------------------ OK --------------------\n",
    "# --deploy-mode\n",
    "# --conf\n",
    "# None of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q13 - Helix\n",
    "\n",
    "# Which of the following is NOT supported as a cluster manager?\n",
    "# YARN\n",
    "# Helix------------------ OK ------------------------\n",
    "# Mesos\n",
    "# Spark\n",
    "# All of the above are supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q14 - Scala, SQL, and HiveQL\n",
    "\n",
    "# Spark SQL allows relational queries to be expressed in which of the \n",
    "# following?\n",
    "# HiveQL only\n",
    "# Scala, SQL, and HiveQL------------------ OK -----------------------\n",
    "# Scala and SQL\n",
    "# Scala and HiveQL\n",
    "# SQL only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q15 - False\n",
    "\n",
    "# Spark Streaming processes live streaming data in real-time. True or false?\n",
    "# True\n",
    "# False------------------- OK ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q16 - All of the above \n",
    "\n",
    "# The MLlib library contains which of the following algorithms?\n",
    "# Dimensionality Reduction\n",
    "# Regression\n",
    "# Classification\n",
    "# Clustering\n",
    "# All of the above--------------------- OK ---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q17 - To perform graph-parallel computations\n",
    "\n",
    "# What is the purpose of the GraphX library?\n",
    "# To create a visual representation of the data\n",
    "# To generate data-parallel models\n",
    "# To create a visual representation of a directed acyclic graph (DAG)\n",
    "# To perform graph-parallel computations------------- OK --------------\n",
    "# To convert from data-parallel to graph-parallel algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q18 - \n",
    "\n",
    "# Which list describes the correct order of precedence for Spark  \n",
    "# configuration, from highest to lowest?\n",
    "# Properties set on SparkConf, values in spark-defaults.conf, flags passed to \n",
    "# spark-submit--- FAUX\n",
    "# Flags passed to spark-submit, values in spark-defaults.conf, properties set \n",
    "# on SparkConf--- FAUX\n",
    "# Values in spark-defaults.conf, properties set on SparkConf, flags passed to\n",
    "# spark-submit---- FAUX\n",
    "# Values in spark-defaults.conf, flags passed to spark-submit, properties set \n",
    "# on SparkConf------ FAUX\n",
    "# Properties set on SparkConf, flags passed to spark-submit, values in \n",
    "# spark-defaults.conf------------ OK -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q19 - True\n",
    "\n",
    "# Spark monitoring can be performed with external tools. True or false?\n",
    "# True----------------- OK ------------------\n",
    "# False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q20 - Java Serialization\n",
    "#       Kyro Serialization\n",
    "\n",
    "# hich serialization libraries are supported in Spark? Select all that apply.\n",
    "# Apache Avro\n",
    "# Java Serialization---------------- OK ------------------\n",
    "# Protocol Buffers\n",
    "# Kyro Serialization---------------- OK ------------------\n",
    "# TPL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
