{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARK FUNDAMENTALS I - REVIEW QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Introduction to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 - Spark makes extensive use of in-memory computations\n",
    "\n",
    "# What gives Spark its speed advantage for complex applications?\n",
    "# Spark extends the MapReduce model\n",
    "# Various libraries provide Spark with additional functionality\n",
    "# Spark can cover a wide range of workloads under one system\n",
    "# Spark makes extensive use of in-memory computations------- OK ------------\n",
    "# All of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Q2 - Programming with Spark’s API  \n",
    "#       Developing a data processing system\n",
    "#       uning an application for a business use case\n",
    "\n",
    "# For what purpose would an Engineer use Spark? Select all that apply.\n",
    "# Analyzing data to obtain insights\n",
    "# Programming with Spark’s API-------------- OK ------------------------\n",
    "# Transforming data into a useable form for analysis\n",
    "# Developing a data processing system---------------- OK ---------------\n",
    "# Tuning an application for a business use case--------------- OK -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Q3 - RDDs allow Spark to reconstruct transformations\n",
    "#       RDDs only add a small amount of code due to tight integration\n",
    "#       RDD is a distributed collection of elements parallelized across the \n",
    "#       cluster.\n",
    "\n",
    "# Which of the following statements are true of the Resilient Distributed \n",
    "# Dataset (RDD)? Select all that apply.\n",
    "# There are three types of RDD operations.\n",
    "# RDDs allow Spark to reconstruct transformations------- OK ------------------\n",
    "# RDDs only add a small amount of code due to tight integration----- OK ------\n",
    "# RDD action operations do not return a value\n",
    "# RDD is a distributed collection of elements parallelized across the cluster.\n",
    "# ------------------------------- ok -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Resilient Distributed Dataset and DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 - Parallelizing an existing Spark collection\n",
    "#      Referencing a Hadoop-supported dataset\n",
    "#      Transforming an existing RDD to form a new one\n",
    "\n",
    "# Which of the following methods can be used to create a Resilient Distributed\n",
    "# Dataset (RDD)? Select all that apply.\n",
    "# Creating a directed acyclic graph (DAG)\n",
    "# Parallelizing an existing Spark collection---------- OK ----------------\n",
    "# Referencing a Hadoop-supported dataset-------------- OK ----------------\n",
    "# Using data that resides in Spark\n",
    "# Transforming an existing RDD to form a new one------ OK ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 - All of the above\n",
    "\n",
    "# What happens when an action is executed?\n",
    "# Executors prepare the data for operation in parallel\n",
    "# The driver sends code to be executed on each block\n",
    "# A cache is created for storing partial results in memory\n",
    "# Data is partitioned into different blocks across the cluster\n",
    "# All of the above---------------------- OK ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 - Persistence through caching provides fault tolerance\n",
    "#      Future actions can be performed significantly faster\n",
    "\n",
    "# Which of the following statements is true of RDD persistence? Select all \n",
    "# that apply.\n",
    "# Persistence through caching provides fault tolerance------- OK -----------\n",
    "# Future actions can be performed significantly faster------- OK -----------\n",
    "# Each partition is replicated on two cluster nodes\n",
    "# RDD persistence always improves space efficiency\n",
    "# By default, objects that are too big for memory are stored on the disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Spark application programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 - An object that represents the connection to a Spark cluster\n",
    "\n",
    "# What is SparkContext?\n",
    "# An object that represents the connection to a Spark cluster----- OK ------\n",
    "# A tool for linking to nodes\n",
    "# A tool that provides fault tolerance\n",
    "# The built-in shell for the Spark engine\n",
    "# A programming language for applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 - Passing by reference\n",
    "#      Static methods in a global singleton\n",
    "#      Anonymous function syntax\n",
    "\n",
    "# # Which of the following methods can be used to pass functions to Spark? \n",
    "# Select all that apply.\n",
    "# Transformations and actions\n",
    "# Passing by reference------------------------ OK ---------------------------\n",
    "# Static methods in a global singleton-------- OK ---------------------------\n",
    "# Import statements\n",
    "# Anonymous function syntax------------------- OK ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 - All of the above\n",
    "\n",
    "# Which of the following is a main component of a Spark application’s source \n",
    "# code?\n",
    "# SparkContext object\n",
    "# Transformations and actions\n",
    "# Business Logic\n",
    "# Import statements\n",
    "# All of the above--------------------- OK -----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4: Introduction to the Spark libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 - Hive\n",
    "\n",
    "# Which of the following is NOT an example of a Spark library?\n",
    "# Hive----------------- OK ---------------------------------------\n",
    "# MLlib\n",
    "# Spark Streaming\n",
    "# Spark SQL\n",
    "# GraphX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 - Kafka\n",
    "#      HDFS\n",
    "\n",
    "# From which of the following sources can Spark Streaming receive data? Select \n",
    "# all that apply.\n",
    "# Kafka------------------- OK --------------------\n",
    "# JSON\n",
    "# Parquet\n",
    "# HDFS------------------- OK --------------------\n",
    "# Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 - False\n",
    "\n",
    "# In Spark Streaming, processing begins immediately when an element of the \n",
    "# application is executed. True or false?\n",
    "# True\n",
    "# False------------------------- OK ---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5: Spark configuration, monitoring and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 - Driver Program\n",
    "#      Cluster Manager\n",
    "#      Worker node\n",
    "\n",
    "# Which of the following is a main component of a Spark cluster? Select all \n",
    "# that apply.\n",
    "# Driver Program--------------------- OK ------------------------------\n",
    "# SparkContext\n",
    "# Cluster Manager-------------------- OK ------------------------------\n",
    "# Worker node------------------------ OK ------------------------------\n",
    "# Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 - The SparkConf object\n",
    "#      Environment variables\n",
    "#      Logging properties\n",
    "\n",
    "# What are the main locations for Spark configuration? Select all that apply.\n",
    "# The SparkConf object---------------------- OK -----------------------\n",
    "# The Spark Shell\n",
    "# Executor Processes\n",
    "# Environment variables--------------------- OK -----------------------\n",
    "# Logging properties------------------------ OK -----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 - Memory Tuning\n",
    "#      Data Serialization\n",
    "#      Using Broadcast variables\n",
    "\n",
    "# Which of the following techniques can improve Spark performance? Select all \n",
    "# that apply.\n",
    "# Scheduler Configuration\n",
    "# Memory Tuning------------------------ OK --------------------------\n",
    "# Data Serialization------------------- OK --------------------------\n",
    "# Using Broadcast variables------------ OK --------------------------\n",
    "# Using nested structures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
