{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HADOOP - FINAL EXAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 - Large files, streaming data access, and commodity hardware\n",
    "\n",
    "# HDFS is designed for:\n",
    "# Large files, streaming data access, and commodity hardware---- OK ---\n",
    "# Large files, low latency data access, and commodity hardware\n",
    "# Large files, streaming data access, and high-end hardware\n",
    "# Small files, streaming data access, and commodity hardware\n",
    "# None of the options is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 - False\n",
    "\n",
    "# The Hadoop distributed file system (HDFS) is the only distributed file\n",
    "# system supported by Hadoop. \n",
    "# True or false?\n",
    "# True\n",
    "# False-------------------- OK -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 - list( < k2, v2 > )\n",
    "\n",
    "# The input to a mapper takes the form < k1, v1 > . What form does the mapper's\n",
    "# output take?\n",
    "# < list(k2), v2 >\n",
    "# list( < k2, v2 > )-------------- OK ---------------\n",
    "# < k2, list(v2) >\n",
    "# < k1, v1 >\n",
    "# None of the options is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4 - A service for moving large amounts of data around a cluster soon after \n",
    "#      the data is produced.\n",
    "\n",
    "# What is Flume?\n",
    "# A service for moving large amounts of data around a cluster soon after the \n",
    "# data is produced.-------------- OK ------------------\n",
    "# A distributed file system.\n",
    "# A programming language that translates high-level queries into map tasks and \n",
    "# reduce tasks.\n",
    "# A platform for executing MapReduce jobs.\n",
    "# None of the options is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 - To transfer each mapper's output to the appropriate reducer node based\n",
    "#       on a partitioning function.\n",
    "\n",
    "# 5. What is the purpose of the shuffle operation in Hadoop MapReduce?\n",
    "# To pre-sort the data before it enters each mapper node.\n",
    "# To distribute input splits among mapper nodes.\n",
    "# To transfer each mapper's output to the appropriate reducer node based on a\n",
    "# partitioning function.--------------- OK -----------------\n",
    "# To randomly distribute mapper output among reducer nodes.\n",
    "# None of the options is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6 - Store and retrieve blocks when told to by clients or the NameNode.\n",
    "\n",
    "# Which of the following is a duty of the DataNodes in HDFS?\n",
    "# Control the execution of an individual map task or a reduce task.\n",
    "# Maintain the file system tree and metadata for all files and directories.\n",
    "# Manage the file system namespace.\n",
    "# Store and retrieve blocks when told to by clients or the NameNode.--- OK ---\n",
    "# None of the options is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7 - Maintain the file system tree and metadata for all files and directories\n",
    "\n",
    "# Which of the following is a duty of the NameNode in HDFS?\n",
    "# Control the MapReduce job from end-to-end\n",
    "# Maintain the file system tree and metadata for all files and directories--OK-\n",
    "# Store the block data\n",
    "# Transfer block data from the data nodes to the clients\n",
    "# None of the options is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8 - JobTracker\n",
    "\n",
    "# Which component determines the specific nodes that a MapReduce task will run\n",
    "# on?\n",
    "# The NameNode\n",
    "# The JobTracker---------------------- OK ------------------\n",
    "# The TaskTrackers \n",
    "# The JobClient    \n",
    "# None of the options is correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9 - All translate high-level languages to MapReduce jobs\n",
    "\n",
    "# Which of the following characteristics is common to Pig, Hive, and Jaql?\n",
    "# All translate high-level languages to MapReduce jobs--------- OK ---------\n",
    "# All operate on JSON data structures\n",
    "# All are data flow languages\n",
    "# All support random reads/writes\n",
    "# None of the options is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10 - Jackal\n",
    "\n",
    "# Which of the following is NOT an open source project related to Hadoop?\n",
    "# Pig\n",
    "# UIMA\n",
    "# Jackal----------------- OK ---------------------------\n",
    "# Avro\n",
    "# Lucene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11 - False\n",
    "\n",
    "# During the replication process, a block of data is written to all specified \n",
    "# DataNodes in parallel. True or false?\n",
    "# True\n",
    "# False-------------------- OK -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q12 - True\n",
    "\n",
    "# With IBM BigInsights, Hadoop components can be started and stopped from a \n",
    "# command line and from the Ambari Console. True or false?\n",
    "# True-------------------------- OK -----------------------\n",
    "# False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q13 - False\n",
    "\n",
    "# When loading data into HDFS, data is held at the NameNode until the block is \n",
    "# filled and then the data is sent to a DataNode. True or false?\n",
    "# True\n",
    "# False-------------------------- OK ------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q14 - Allows multiple NameNodes with their own namespaces to share a pool of \n",
    "#       DataNodes\n",
    "\n",
    "# Which of the following is true about the Hadoop federation?\n",
    "# Uses JournalNodes to decide the active NameNode FAUX\n",
    "# Allows non-Hadoop programs to access data in HDFS\n",
    "# Allows multiple NameNodes with their own namespaces to share a pool of \n",
    "# DataNodes------------------ OK --------------------------\n",
    "# Implements a resource manager external to all Hadoop frameworks FAUX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q15 - Uses JournalNodes to decide the active NameNode\n",
    "\n",
    "# Which of the following is true about Hadoop high availability?\n",
    "# Uses JournalNodes to decide the active NameNode----- OK ---------\n",
    "# Allows non-Hadoop programs to access data in HDFS\n",
    "# Allows multiple NameNodes with their own namespaces to share a pool of DataNodes\n",
    "# Implements a resource manager external to all Hadoop frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q16 - Implements a resource manager external to all Hadoop frameworks\n",
    "\n",
    "# Which of the following is true about YARN?\n",
    "# Uses JournalNodes to decide the active NameNode\n",
    "# Allows non-Hadoop programs to access data in HDFS\n",
    "# Allows multiple NameNodes with their own namespaces to share a pool of DataNodes\n",
    "# Implements a resource manager external to all Hadoop frameworks--- OK ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q17 - None of the options is correct\n",
    "\n",
    "# Which of the following sentences is true?\n",
    "# Hadoop is good for OLTP, DSS, and big data\n",
    "# Hadoop includes open source components and closed source components\n",
    "# Hadoop is a new technology designed to replace relational databases\n",
    "# All of the options are correct\n",
    "# None of the options is correct------------------ OK ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q18 - Processing billions of email messages to perform text analytic\n",
    "\n",
    "# In which of these scenarios should Hadoop be used?\n",
    "# Processing billions of email messages to perform text analytics--- OK ----\n",
    "# Obtaining stock price trends on a per-minute basis\n",
    "# Processing weather sensor information to predict a hurricane path\n",
    "# Analyzing vital signs of a baby in real time\n",
    "# None of the options is correct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
